# Supported datasets
SEGMENTATION_DATASETS: {'voc': 'PASCAL_VOC', 'city': 'CITYSCAPES', 'synthia': 'SYNTHIA', 'gtav': 'GTAV'}
LANE_DATASETS: {'tusimple': 'TUSIMPLE', 'culane': 'CULANE'}

GENERAL:  # ImageNet pre-trained model's general statistics
    MEAN: [0.485, 0.456, 0.406]
    STD: [0.229, 0.224, 0.225]

PASCAL_VOC:  # PASCAL VOC 2012
    BASE_DIR: 'data/VOCtrainval_11-May-2012/VOCdevkit/VOC2012'
    # training crop size/deprecated/testing label size
    SIZES: [ !!python/tuple [321, 321], !!python/tuple [505, 505], !!python/tuple [505, 505] ]
    NUM_CLASSES: 21
    COLORS: [ [ 0, 0, 0 ],
              [ 128, 0, 0 ], [ 0, 128, 0 ], [ 128, 128, 0 ], [ 0, 0, 128 ],
              [ 128, 0, 128 ], [ 0, 128, 128 ], [ 128, 128, 128 ], [ 64, 0, 0 ],
              [ 192, 0, 0 ], [ 64, 128, 0 ], [ 192, 128, 0 ], [ 64, 0, 128 ],
              [ 192, 0, 128 ], [ 64, 128, 128 ], [ 192, 128, 128 ], [ 0, 64, 0 ],
              [ 128, 64, 0 ], [ 0, 192, 0 ], [ 128, 192, 0 ], [ 0, 64, 128 ],
              [ 255, 255, 255 ] ]
    CATEGORIES: [ 'Background',
                  'Aeroplane', 'Bicycle', 'Bird', 'Boat',
                  'Bottle', 'Bus', 'Car', 'Cat',
                  'Chair', 'Cow', 'Diningtable', 'Dog',
                  'Horse', 'Motorbike', 'Person', 'Pottedplant',
                  'Sheep', 'Sofa', 'Train', 'Tvmonitor' ]

CITYSCAPES:  # Cityscapes
    BASE_DIR: '../../dataset/cityscapes'
    # training crop size/deprecated/testing label size
    SIZES: [ !!python/tuple [256, 512], !!python/tuple [512, 1024], !!python/tuple [512, 1024] ]
    # input/encoder output/testing label size
    SIZES_ERFNET: [ !!python/tuple [512, 1024], !!python/tuple [64, 128], !!python/tuple [512, 1024] ]
    # training crop size/deprecated/testing label size
    SIZES_BIG: [ !!python/tuple [512, 1024], !!python/tuple [512, 1024], !!python/tuple [1024, 2048] ]
    WEIGHTS_ERFNET: [ 2.8149201869965, 6.9850029945374, 3.7890393733978, 9.9428062438965,
                      9.7702074050903, 9.5110931396484, 10.311357498169, 10.026463508606,
                      4.6323022842407, 9.5608062744141, 7.8698215484619, 9.5168733596802,
                      10.373730659485, 6.6616044044495, 10.260489463806, 10.287888526917,
                      10.289801597595, 10.405355453491, 10.138095855713 ]
    NUM_CLASSES: 19
    COLORS: [ [ 128, 64, 128 ], [ 244, 35, 232 ], [ 70, 70, 70 ], [ 102, 102, 156 ],
              [ 190, 153, 153 ], [ 153, 153, 153 ], [ 250, 170, 30 ], [ 220, 220, 0 ],
              [ 107, 142, 35 ], [ 152, 251, 152 ], [ 70, 130, 180 ], [ 220, 20, 60 ],
              [ 255, 0, 0 ], [ 0, 0, 142 ], [ 0, 0, 70 ], [ 0, 60, 100 ],
              [ 0, 80, 100 ], [ 0, 0, 230 ], [ 119, 11, 32 ],
              [ 0, 0, 0 ] ]
    CATEGORIES: [ 'road', 'sidewalk', 'building', 'wall',
                  'fence', 'pole', 'traffic light', 'traffic sign',
                  'vegetation', 'terrain', 'sky', 'person',
                  'rider', 'car', 'truck', 'bus',
                  'train', 'motorcycle', 'bicycle' ]
    CITIES: [ 'aachen', 'bremen', 'darmstadt', 'erfurt', 'hanover',
              'krefeld', 'strasbourg', 'tubingen', 'weimar', 'bochum',
              'cologne', 'dusseldorf', 'hamburg', 'jena', 'monchengladbach',
              'stuttgart', 'ulm', 'zurich' ]
    LABEL_ID_MAP: [ 255, 255, 255, 255, 255, 255, 255,
                    0,   1,   255, 255, 2,   3,   4,
                    255, 255, 255, 5,   255, 6,   7,
                    8,   9,   10,  11,  12,  13,  14,
                    15,  255, 255, 16,  17,  18 ]

SYNTHIA:  # Synthia (23 classes, ignore as black, no such thing as background, mapped to Cityscapes)
    BASE_DIR: '../../dataset/syn/SYNTHIA_RAND_CITYSCPAES'
    # training crop size/original size/testing label size on Cityscapes
    SIZES: [ !!python/tuple [512, 1024], !!python/tuple [760, 1280], !!python/tuple [1024, 2048] ]
    NUM_CLASSES: 19  # Set same as Cityscapes
    COLORS: [ [ 128, 64, 128 ], [ 244, 35, 232 ], [ 70, 70, 70 ], [ 102, 102, 156 ],
              [ 190, 153, 153 ], [ 153, 153, 153 ], [ 250, 170, 30 ], [ 220, 220, 0 ],
              [ 107, 142, 35 ], [ 152, 251, 152 ], [ 70, 130, 180 ], [ 220, 20, 60 ],
              [ 255, 0, 0 ], [ 0, 0, 142 ], [ 0, 0, 70 ], [ 0, 60, 100 ],
              [ 0, 80, 100 ], [ 0, 0, 230 ], [ 119, 11, 32 ],
              [ 0, 0, 0 ] ]
    CATEGORIES: [ 'road', 'sidewalk', 'building', 'wall',
                  'fence', 'pole', 'traffic light', 'traffic sign',
                  'vegetation', 'terrain', 'sky', 'person',
                  'rider', 'car', 'truck', 'bus',
                  'train', 'motorcycle', 'bicycle' ]
    LABEL_ID_MAP: [ 255, 10,  2,   0, 1,   4,
                    8,   5,   13,  7, 11,  18,
                    17,  255, 255, 6, 9,   12,
                    14,  15,  16,  3, 255 ]
    IOU_13: [0, 1, 2, 6, 7, 8, 10, 11, 12, 13, 15, 17, 18]
    IOU_16: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 17, 18]

GTAV:  # GTAV (19 classes, ignore as black, no such thing as background)
    BASE_DIR: '../../dataset/gtav'
    # training crop size/original size/testing label size on Cityscapes
    SIZES: [ !!python/tuple [512, 1024], !!python/tuple [1054, 1912], !!python/tuple [1024, 2048] ]
    NUM_CLASSES: 19
    COLORS: [ [ 128, 64, 128 ], [ 244, 35, 232 ], [ 70, 70, 70 ], [ 102, 102, 156 ],
              [ 190, 153, 153 ], [ 153, 153, 153 ], [ 250, 170, 30 ], [ 220, 220, 0 ],
              [ 107, 142, 35 ], [ 152, 251, 152 ], [ 70, 130, 180 ], [ 220, 20, 60 ],
              [ 255, 0, 0 ], [ 0, 0, 142 ], [ 0, 0, 70 ], [ 0, 60, 100 ],
              [ 0, 80, 100 ], [ 0, 0, 230 ], [ 119, 11, 32 ],
              [ 0, 0, 0 ] ]
    CATEGORIES: [ 'road', 'sidewalk', 'building', 'wall',
                  'fence', 'pole', 'traffic light', 'traffic sign',
                  'vegetation', 'terrain', 'sky', 'person',
                  'rider', 'car', 'truck', 'bus',
                  'train', 'motorcycle', 'bicycle' ]

TUSIMPLE:  # TuSimple
    BASE_DIR: '../../dataset/tusimple'
    # training size/original size
    SIZES: [ !!python/tuple [360, 640], !!python/tuple [720, 1280] ]
    NUM_CLASSES: 7
    WEIGHTS: [0.4, 1, 1, 1, 1, 1, 1]
    GAP: 10  # Y pixel gap per sampling point
    PPL: 56  # Points per lane
    THRESHOLD: 0.3  # Threshold for lane generation from segmentation mask

CULANE:  # CULane
    BASE_DIR: '../../dataset/culane'
    # training size/original size
    SIZES: [ !!python/tuple [288, 800], !!python/tuple [590, 1640] ]
    NUM_CLASSES: 5
    WEIGHTS: [0.4, 1, 1, 1, 1]
    GAP: 20  # Y pixel gap per sampling point
    PPL: 18  # Points per lane
    THRESHOLD: 0.3  # Threshold for lane generation from segmentation mask
